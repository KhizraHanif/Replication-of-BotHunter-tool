{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4652 entries, 0 to 4651\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype\n",
      "---  ------         --------------  -----\n",
      " 0   login          4652 non-null   int32\n",
      " 1   Account tag    4652 non-null   int32\n",
      " 2   Account name   4652 non-null   int32\n",
      " 3   Account bio    4652 non-null   int32\n",
      " 4   Account login  4652 non-null   int32\n",
      " 5   Type           4652 non-null   int32\n",
      " 6   Data_Source    4652 non-null   int32\n",
      "dtypes: int32(7)\n",
      "memory usage: 127.3 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4883 entries, 0 to 4882\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype\n",
      "---  ------         --------------  -----\n",
      " 0   login          4883 non-null   int32\n",
      " 1   Account tag    4883 non-null   int32\n",
      " 2   Account name   4883 non-null   int32\n",
      " 3   Account bio    4883 non-null   int32\n",
      " 4   Account login  4883 non-null   int32\n",
      " 5   Type           4883 non-null   int32\n",
      " 6   Data_Source    4883 non-null   int32\n",
      "dtypes: int32(7)\n",
      "memory usage: 133.6 KB\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 95\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mfor\u001b[39;00m train_index, test_index \u001b[39min\u001b[39;00m skf_issue_bots\u001b[39m.\u001b[39msplit(X, y):\n\u001b[0;32m     94\u001b[0m     X_train_issue_bots, X_test_issue_bots \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39miloc[train_index], X\u001b[39m.\u001b[39miloc[test_index]\n\u001b[1;32m---> 95\u001b[0m     X_train_issue_bots_text, X_test_issue_bots_text \u001b[39m=\u001b[39m X_text[X_text\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39misin(train_index)], X_text[X_text\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39misin(test_index)]\n\u001b[0;32m     97\u001b[0m     \u001b[39m# Preprocess text features using CountVectorizer\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     count_vectorizer \u001b[39m=\u001b[39m CountVectorizer()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_text' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Oracle.csv')\n",
    "selected_features = ['login', 'Total number of Repo activities', 'Unique number of Repo activities',\n",
    "                     'Total number of PR activities', 'Unique number of PR activities',\n",
    "                     'Total number of Issue activities', 'Unique number of Issue activities',\n",
    "                     'Total number of Commit activities', 'Unique number of Commit activities',\n",
    "                     'Number of following', 'Number of followers',\n",
    "                     'Account tag', 'Account name', 'Account bio', 'Account login',\n",
    "                     'Median Activity per Day', 'Median Creation Time of the first activities',\n",
    "                     'Text similarity', 'Text similarity of Comments Before Bot',\n",
    "                     'Text similarity of Commit Messages', 'Type', 'Data_Source']\n",
    "df = df[selected_features]\n",
    "\n",
    "# Identify text and int features\n",
    "text_features = ['login', 'Account tag', 'Account name', 'Account bio', 'Account login', 'Type', 'Data_Source']\n",
    "int_features = [col for col in df.columns if col not in text_features]\n",
    "\n",
    "# Preprocess text features using LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for feature in text_features:\n",
    "    df[feature] = label_encoder.fit_transform(df[feature].astype(str))\n",
    "\n",
    "# Remove correlated features\n",
    "numeric_columns = df[int_features].select_dtypes(include=np.number).columns\n",
    "corr_matrix = df[numeric_columns].corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column])]\n",
    "df = df.drop(columns=to_drop)\n",
    "\n",
    "# Split features and target variable\n",
    "X = df.drop(columns=['Type', 'Data_Source'])\n",
    "y = df['Type']\n",
    "\n",
    "# Scale the input features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 6: One-hot encode text features using CountVectorizer\n",
    "X_text_encoded = pd.get_dummies(df[text_features])\n",
    "\n",
    "bots_df = df[df['Type'] == 0]\n",
    "humans_df = df[df['Type'] == 1]\n",
    "\n",
    "# Step 13: Split bots into 'issue_bots' and 'commit_bots' datasets\n",
    "issue_bots = bots_df[bots_df['Data_Source'] == 1]\n",
    "commit_bots = bots_df[bots_df['Data_Source'] == 0]\n",
    "\n",
    "# Step 14: Add human accounts to both datasets\n",
    "issue_bots_df = pd.concat([issue_bots, humans_df], ignore_index=True)\n",
    "commit_bots_df = pd.concat([commit_bots, humans_df], ignore_index=True)\n",
    "commit_bots_df.info()\n",
    "issue_bots_df.info()\n",
    "\n",
    "# Step 7: Initialize classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support-Vector Machine': SVC(probability=True)\n",
    "}\n",
    "\n",
    "# Step 8: Evaluating classifiers on issue_bots and commit_bots datasets\n",
    "results_issue_bots = {}\n",
    "results_commit_bots = {}\n",
    "skf_issue_bots = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "skf_commit_bots = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for clf_name, clf in classifiers.items():\n",
    "    precision_list_issue_bots = []\n",
    "    recall_list_issue_bots = []\n",
    "    f1_list_issue_bots = []\n",
    "    auc_list_issue_bots = []\n",
    "    precision_list_commit_bots = []\n",
    "    recall_list_commit_bots = []\n",
    "    f1_list_commit_bots = []\n",
    "    auc_list_commit_bots = []\n",
    "\n",
    "    for train_index, test_index in skf_issue_bots.split(X, y):\n",
    "        X_train_issue_bots, X_test_issue_bots = X.iloc[train_index], X.iloc[test_index]\n",
    "        X_train_issue_bots_text, X_test_issue_bots_text = X_text[X_text.index.isin(train_index)], X_text[X_text.index.isin(test_index)]\n",
    "\n",
    "        # Preprocess text features using CountVectorizer\n",
    "        count_vectorizer = CountVectorizer()\n",
    "        X_train_issue_bots_text_encoded = count_vectorizer.fit_transform(X_train_issue_bots_text.astype(str).sum(axis=1))\n",
    "        X_test_issue_bots_text_encoded = count_vectorizer.transform(X_test_issue_bots_text.astype(str).sum(axis=1))\n",
    "\n",
    "        # Combine one-hot encoded text features with other numerical features\n",
    "        X_train_issue_bots_text_encoded_df = pd.DataFrame(X_train_issue_bots_text_encoded.toarray()).add_prefix('text_')\n",
    "        X_test_issue_bots_text_encoded_df = pd.DataFrame(X_test_issue_bots_text_encoded.toarray()).add_prefix('text_')\n",
    "        X_train_issue_bots = pd.concat([X_train_issue_bots.reset_index(drop=True), X_train_issue_bots_text_encoded_df], axis=1)\n",
    "        X_test_issue_bots = pd.concat([X_test_issue_bots.reset_index(drop=True), X_test_issue_bots_text_encoded_df], axis=1)\n",
    "\n",
    "        clf.fit(X_train_issue_bots, y[train_index])\n",
    "        y_pred_issue_bots = clf.predict(X_test_issue_bots)\n",
    "\n",
    "        precision_list_issue_bots.append(precision_score(y[test_index], y_pred_issue_bots))\n",
    "        recall_list_issue_bots.append(recall_score(y[test_index], y_pred_issue_bots))\n",
    "        f1_list_issue_bots.append(f1_score(y[test_index], y_pred_issue_bots))\n",
    "        auc_list_issue_bots.append(roc_auc_score(y[test_index], clf.predict_proba(X_test_issue_bots)[:, 1]))\n",
    "\n",
    "    results_issue_bots[clf_name] = {\n",
    "        'Precision (%)': sum(precision_list_issue_bots) / len(precision_list_issue_bots) * 100,\n",
    "        'Recall (%)': sum(recall_list_issue_bots) / len(recall_list_issue_bots) * 100,\n",
    "        'F1-score (%)': sum(f1_list_issue_bots) / len(f1_list_issue_bots) * 100,\n",
    "        'AUC (%)': sum(auc_list_issue_bots) / len(auc_list_issue_bots) * 100,\n",
    "    }\n",
    "\n",
    "    for train_index, test_index in skf_commit_bots.split(X, y):\n",
    "        X_train_commit_bots, X_test_commit_bots = X.iloc[train_index], X.iloc[test_index]\n",
    "        X_train_commit_bots_text, X_test_commit_bots_text = X_text[X_text.index.isin(train_index)], X_text[X_text.index.isin(test_index)]\n",
    "\n",
    "        # Preprocess text features using CountVectorizer\n",
    "        count_vectorizer = CountVectorizer()\n",
    "        X_train_commit_bots_text_encoded = count_vectorizer.fit_transform(X_train_commit_bots_text.astype(str).sum(axis=1))\n",
    "        X_test_commit_bots_text_encoded = count_vectorizer.transform(X_test_commit_bots_text.astype(str).sum(axis=1))\n",
    "\n",
    "        # Combine one-hot encoded text features with other numerical features\n",
    "        X_train_commit_bots_text_encoded_df = pd.DataFrame(X_train_commit_bots_text_encoded.toarray()).add_prefix('text_')\n",
    "        X_test_commit_bots_text_encoded_df = pd.DataFrame(X_test_commit_bots_text_encoded.toarray()).add_prefix('text_')\n",
    "        X_train_commit_bots = pd.concat([X_train_commit_bots.reset_index(drop=True), X_train_commit_bots_text_encoded_df], axis=1)\n",
    "        X_test_commit_bots = pd.concat([X_test_commit_bots.reset_index(drop=True), X_test_commit_bots_text_encoded_df], axis=1)\n",
    "\n",
    "        clf.fit(X_train_commit_bots, y[train_index])\n",
    "        y_pred_commit_bots = clf.predict(X_test_commit_bots)\n",
    "\n",
    "        precision_list_commit_bots.append(precision_score(y[test_index], y_pred_commit_bots))\n",
    "        recall_list_commit_bots.append(recall_score(y[test_index], y_pred_commit_bots))\n",
    "        f1_list_commit_bots.append(f1_score(y[test_index], y_pred_commit_bots))\n",
    "        auc_list_commit_bots.append(roc_auc_score(y[test_index], clf.predict_proba(X_test_commit_bots)[:, 1]))\n",
    "\n",
    "    results_commit_bots[clf_name] = {\n",
    "        'Precision (%)': sum(precision_list_commit_bots) / len(precision_list_commit_bots) * 100,\n",
    "        'Recall (%)': sum(recall_list_commit_bots) / len(recall_list_commit_bots) * 100,\n",
    "        'F1-score (%)': sum(f1_list_commit_bots) / len(f1_list_commit_bots) * 100,\n",
    "        'AUC (%)': sum(auc_list_commit_bots) / len(auc_list_commit_bots) * 100,\n",
    "    }\n",
    "\n",
    "# Step 9: Display the results for Table 4 (Issue Bots)\n",
    "print(\"Table 4: Performance of classifiers on issue_bots dataset:\")\n",
    "print(pd.DataFrame(results_issue_bots).transpose())\n",
    "\n",
    "# Step 10: Display the results for Table 4 (Commit Bots)\n",
    "print(\"\\nTable 4: Performance of classifiers on commit_bots dataset:\")\n",
    "print(pd.DataFrame(results_commit_bots).transpose())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
