{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 4: Performance of classifiers on issue_bots dataset:\n",
      "                        Precision (%)  Recall (%)  F1-score (%)    AUC (%)\n",
      "Logistic Regression         97.405248   98.961012     98.174937  88.561961\n",
      "K-Nearest Neighbors         91.367499   98.938797     95.001887  64.313776\n",
      "Decision Tree               97.533460   98.915866     98.218060  87.269527\n",
      "Random Forest               97.620110   98.938439     98.273301  89.387692\n",
      "Support-Vector Machine      90.682012  100.000000     95.113310  59.253302\n",
      "\n",
      "Table 4: Performance of classifiers on commit_bots dataset:\n",
      "                        Precision (%)  Recall (%)  F1-score (%)    AUC (%)\n",
      "Logistic Regression         98.921507   98.961472     98.939920  93.226822\n",
      "K-Nearest Neighbors         95.256783   99.774164     97.463020  58.853956\n",
      "Decision Tree               99.123401   99.164581     99.142759  90.906401\n",
      "Random Forest               98.764460   99.074339     98.918073  93.000488\n",
      "Support-Vector Machine      95.184919  100.000000     97.533038  53.562757\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Oracle.csv')\n",
    "\n",
    "selected_features = ['login', 'Total number of Repo activities', 'Unique number of Repo activities',\n",
    "                     'Total number of PR activities', 'Unique number of PR activities',\n",
    "                     'Total number of Issue activities', 'Unique number of Issue activities',\n",
    "                     'Total number of Commit activities', 'Unique number of Commit activities',\n",
    "                     'Number of following', 'Number of followers',\n",
    "                     'Account tag', 'Account name', 'Account bio', 'Account login',\n",
    "                     'Median Activity per Day', 'Median Creation Time of the first activities',\n",
    "                     'Text similarity', 'Text similarity of Comments Before Bot',\n",
    "                     'Text similarity of Commit Messages', 'Type', 'Data_Source']\n",
    "\n",
    "df = df[selected_features]\n",
    "\n",
    "# Identify text and int features\n",
    "text_features = ['login', 'Account tag', 'Account name', 'Account bio', 'Account login', 'Type', 'Data_Source']\n",
    "int_features = [col for col in df.columns if col not in text_features]\n",
    "\n",
    "# Preprocess text features using LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for feature in text_features:\n",
    "    df[feature] = label_encoder.fit_transform(df[feature].astype(str))\n",
    "\n",
    "# Remove correlated features\n",
    "numeric_columns = df[int_features].select_dtypes(include=np.number).columns\n",
    "corr_matrix = df[numeric_columns].corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column])]\n",
    "df = df.drop(columns=to_drop)\n",
    "\n",
    "# Split features and target variable\n",
    "X = df.drop(columns=['Type', 'Data_Source'])\n",
    "y = df['Type']\n",
    "\n",
    "# Scale the input features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 6: One-hot encode text features using CountVectorizer\n",
    "X_text_encoded = pd.get_dummies(df[text_features])\n",
    "\n",
    "bots_df = df[df['Type'] == 0]\n",
    "humans_df = df[df['Type'] == 1]\n",
    "\n",
    "# Step 13: Split bots into 'issue_bots' and 'commit_bots' datasets\n",
    "issue_bots = bots_df[bots_df['Data_Source'] == 1]\n",
    "commit_bots = bots_df[bots_df['Data_Source'] == 0]\n",
    "\n",
    "# Step 14: Add human accounts to both datasets\n",
    "issue_bots_df = pd.concat([issue_bots, humans_df], ignore_index=True)\n",
    "commit_bots_df = pd.concat([commit_bots, humans_df], ignore_index=True)\n",
    "\n",
    "# Split features and target variable for issue_bots dataset\n",
    "X_issue_bots = issue_bots_df.drop(columns=['Type', 'Data_Source'])\n",
    "y_issue_bots = issue_bots_df['Type']\n",
    "\n",
    "# Split features and target variable for commit_bots dataset\n",
    "X_commit_bots = commit_bots_df.drop(columns=['Type', 'Data_Source'])\n",
    "y_commit_bots = commit_bots_df['Type']\n",
    "\n",
    "# Step 7: Initialize classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support-Vector Machine': SVC(probability=True)\n",
    "}\n",
    "\n",
    "# Step 8: Evaluating classifiers on issue_bots and commit_bots datasets\n",
    "results_issue_bots = {}\n",
    "results_commit_bots = {}\n",
    "skf_issue_bots = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "skf_commit_bots = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for clf_name, clf in classifiers.items():\n",
    "    precision_list_issue_bots = []\n",
    "    recall_list_issue_bots = []\n",
    "    f1_list_issue_bots = []\n",
    "    auc_list_issue_bots = []\n",
    "    precision_list_commit_bots = []\n",
    "    recall_list_commit_bots = []\n",
    "    f1_list_commit_bots = []\n",
    "    auc_list_commit_bots = []\n",
    "\n",
    "    # Inside the for loop for issue_bots\n",
    "    for train_index, test_index in skf_issue_bots.split(X_issue_bots, y_issue_bots):\n",
    "        X_train_issue_bots, X_test_issue_bots = X_issue_bots.iloc[train_index], X_issue_bots.iloc[test_index]\n",
    "        X_train_issue_bots_text, X_test_issue_bots_text = X_text_encoded[X_text_encoded.index.isin(train_index)], X_text_encoded[X_text_encoded.index.isin(test_index)]\n",
    "\n",
    "        # Preprocess text features using CountVectorizer\n",
    "        count_vectorizer = CountVectorizer()\n",
    "        X_train_issue_bots_text_encoded = count_vectorizer.fit_transform(X_train_issue_bots_text.astype(str).sum(axis=1))\n",
    "        X_test_issue_bots_text_encoded = count_vectorizer.transform(X_test_issue_bots_text.astype(str).sum(axis=1))\n",
    "\n",
    "        # Combine one-hot encoded text features with other numerical features\n",
    "        X_train_issue_bots_text_encoded_df = pd.DataFrame(X_train_issue_bots_text_encoded.toarray()).add_prefix('text_')\n",
    "        X_test_issue_bots_text_encoded_df = pd.DataFrame(X_test_issue_bots_text_encoded.toarray()).add_prefix('text_')\n",
    "        X_train_issue_bots = pd.concat([X_train_issue_bots.reset_index(drop=True), X_train_issue_bots_text_encoded_df], axis=1)\n",
    "        X_test_issue_bots = pd.concat([X_test_issue_bots.reset_index(drop=True), X_test_issue_bots_text_encoded_df], axis=1)\n",
    "\n",
    "        clf.fit(X_train_issue_bots, y_issue_bots.iloc[train_index])\n",
    "        y_pred_issue_bots = clf.predict(X_test_issue_bots)\n",
    "\n",
    "        precision_list_issue_bots.append(precision_score(y_issue_bots.iloc[test_index], y_pred_issue_bots))\n",
    "        recall_list_issue_bots.append(recall_score(y_issue_bots.iloc[test_index], y_pred_issue_bots))\n",
    "        f1_list_issue_bots.append(f1_score(y_issue_bots.iloc[test_index], y_pred_issue_bots))\n",
    "        auc_list_issue_bots.append(roc_auc_score(y_issue_bots.iloc[test_index], clf.predict_proba(X_test_issue_bots)[:, 1]))\n",
    "\n",
    "     # Calculate average precision, recall, F1-score, and AUC for issue_bots\n",
    "    avg_precision_issue_bots = np.nanmean(precision_list_issue_bots)\n",
    "    avg_recall_issue_bots = np.nanmean(recall_list_issue_bots)\n",
    "    avg_f1_issue_bots = np.nanmean(f1_list_issue_bots)\n",
    "    avg_auc_issue_bots = np.nanmean(auc_list_issue_bots)\n",
    "\n",
    "    results_issue_bots[clf_name] = {\n",
    "        'Precision (%)': avg_precision_issue_bots * 100,\n",
    "        'Recall (%)': avg_recall_issue_bots * 100,\n",
    "        'F1-score (%)': avg_f1_issue_bots * 100,\n",
    "        'AUC (%)': avg_auc_issue_bots * 100,\n",
    "    }\n",
    "\n",
    "   # Inside the for loop for commit_bots\n",
    "    for train_index, test_index in skf_commit_bots.split(X_commit_bots, y_commit_bots):\n",
    "        X_train_commit_bots, X_test_commit_bots = X_commit_bots.iloc[train_index], X_commit_bots.iloc[test_index]\n",
    "        X_train_commit_bots_text, X_test_commit_bots_text = X_text_encoded[X_text_encoded.index.isin(train_index)], X_text_encoded[X_text_encoded.index.isin(test_index)]\n",
    "\n",
    "    # Preprocess text features using CountVectorizer\n",
    "        count_vectorizer = CountVectorizer()\n",
    "        X_train_commit_bots_text_encoded = count_vectorizer.fit_transform(X_train_commit_bots_text.astype(str).sum(axis=1))\n",
    "        X_test_commit_bots_text_encoded = count_vectorizer.transform(X_test_commit_bots_text.astype(str).sum(axis=1))\n",
    "\n",
    "    # Combine one-hot encoded text features with other numerical features\n",
    "        X_train_commit_bots_text_encoded_df = pd.DataFrame(X_train_commit_bots_text_encoded.toarray()).add_prefix('text_')\n",
    "        X_test_commit_bots_text_encoded_df = pd.DataFrame(X_test_commit_bots_text_encoded.toarray()).add_prefix('text_')\n",
    "        X_train_commit_bots = pd.concat([X_train_commit_bots.reset_index(drop=True), X_train_commit_bots_text_encoded_df], axis=1)\n",
    "        X_test_commit_bots = pd.concat([X_test_commit_bots.reset_index(drop=True), X_test_commit_bots_text_encoded_df], axis=1)\n",
    "\n",
    "        clf.fit(X_train_commit_bots, y_commit_bots.iloc[train_index])\n",
    "        y_pred_commit_bots = clf.predict(X_test_commit_bots)\n",
    "\n",
    "        precision_list_commit_bots.append(precision_score(y_commit_bots.iloc[test_index], y_pred_commit_bots))\n",
    "        recall_list_commit_bots.append(recall_score(y_commit_bots.iloc[test_index], y_pred_commit_bots))\n",
    "        f1_list_commit_bots.append(f1_score(y_commit_bots.iloc[test_index], y_pred_commit_bots))\n",
    "        auc_list_commit_bots.append(roc_auc_score(y_commit_bots.iloc[test_index], clf.predict_proba(X_test_commit_bots)[:, 1]))\n",
    "\n",
    "    results_commit_bots[clf_name] = {\n",
    "        'Precision (%)': sum(precision_list_commit_bots) / len(precision_list_commit_bots) * 100,\n",
    "        'Recall (%)': sum(recall_list_commit_bots) / len(recall_list_commit_bots) * 100,\n",
    "        'F1-score (%)': sum(f1_list_commit_bots) / len(f1_list_commit_bots) * 100,\n",
    "        'AUC (%)': sum(auc_list_commit_bots) / len(auc_list_commit_bots) * 100,\n",
    "}\n",
    "\n",
    "# Step 9: Display the results for Table 4 (Issue Bots)\n",
    "print(\"Table 4: Performance of classifiers on issue_bots dataset:\")\n",
    "print(pd.DataFrame(results_issue_bots).transpose())\n",
    "\n",
    "# Step 10: Display the results for Table 4 (Commit Bots)\n",
    "print(\"\\nTable 4: Performance of classifiers on commit_bots dataset:\")\n",
    "print(pd.DataFrame(results_commit_bots).transpose())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
