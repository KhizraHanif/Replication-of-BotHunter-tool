{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 3: Performance of the classifiers:\n",
      "                        Precision (%)  Recall (%)  F1-score (%)    AUC (%)\n",
      "Logistic Regression         96.846227   98.938643     97.878478  90.071050\n",
      "K-Nearest Neighbors         87.925350   97.177410     92.318926  65.643179\n",
      "Decision Tree               96.951701   98.938643     97.932735  89.307996\n",
      "Random Forest               96.951701   98.938643     97.932735  90.176585\n",
      "Support-Vector Machine      86.704539  100.000000     92.878868  62.492746\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#  Load the dataset\n",
    "df = pd.read_csv('Oracle.csv')\n",
    "selected_features = ['login', 'Total number of Repo activities', 'Unique number of Repo activities',\n",
    "                     'Total number of PR activities', 'Unique number of PR activities',\n",
    "                     'Total number of Issue activities', 'Unique number of Issue activities',\n",
    "                     'Total number of Commit activities', 'Unique number of Commit activities',\n",
    "                     'Number of following', 'Number of followers',\n",
    "                     'Account tag', 'Account name', 'Account bio', 'Account login',\n",
    "                     'Median Activity per Day', 'Median Creation Time of the first activities',\n",
    "                     'Text similarity', 'Text similarity of Comments Before Bot',\n",
    "                     'Text similarity of Commit Messages', 'Type', 'Data_Source']\n",
    "df = df[selected_features]\n",
    "# Identify text and int features\n",
    "text_features = ['login', 'Account tag', 'Account name', 'Account bio', 'Account login', 'Type', 'Data_Source']\n",
    "int_features = [col for col in df.columns if col not in text_features]\n",
    "\n",
    "#  Preprocess text features using LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for feature in text_features:\n",
    "    df[feature] = label_encoder.fit_transform(df[feature].astype(str))\n",
    "\n",
    "#  Remove correlated features\n",
    "numeric_columns = df[int_features].select_dtypes(include=np.number).columns\n",
    "corr_matrix = df[numeric_columns].corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column])]\n",
    "df = df.drop(columns=to_drop)\n",
    "\n",
    "# Split features and target variable\n",
    "X = df.drop(columns=['Type', 'Data_Source'])\n",
    "y = df['Type']\n",
    "# Scale the input features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# Step 6: One-hot encode text features using CountVectorizer\n",
    "X_text = pd.get_dummies(df[text_features])\n",
    "\n",
    "# Step 7: Initialize classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support-Vector Machine': SVC(probability=True)\n",
    "}\n",
    "\n",
    "# Step 8: Evaluate classifiers using stratified 10-fold cross-validation\n",
    "results = {}\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for clf_name, clf in classifiers.items():\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "    auc_list = []\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        X_train_text, X_test_text = X_text.iloc[train_index], X_text.iloc[test_index]\n",
    "\n",
    "        # Step 9: Preprocess text features using CountVectorizer\n",
    "        count_vectorizer = CountVectorizer()\n",
    "        X_train_text_encoded = count_vectorizer.fit_transform(X_train_text.astype(str).sum(axis=1))\n",
    "        X_test_text_encoded = count_vectorizer.transform(X_test_text.astype(str).sum(axis=1))\n",
    "\n",
    "        # Step 10: Combine one-hot encoded text features with other numerical features\n",
    "        X_train_text_encoded_df = pd.DataFrame(X_train_text_encoded.toarray()).add_prefix('text_')\n",
    "        X_test_text_encoded_df = pd.DataFrame(X_test_text_encoded.toarray()).add_prefix('text_')\n",
    "        X_train = pd.concat([X_train.reset_index(drop=True), X_train_text_encoded_df], axis=1)\n",
    "        X_test = pd.concat([X_test.reset_index(drop=True), X_test_text_encoded_df], axis=1)\n",
    "\n",
    "        clf.fit(X_train, y[train_index])\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        precision_list.append(precision_score(y[test_index], y_pred))\n",
    "        recall_list.append(recall_score(y[test_index], y_pred))\n",
    "        f1_list.append(f1_score(y[test_index], y_pred))\n",
    "        auc_list.append(roc_auc_score(y[test_index], clf.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "    results[clf_name] = {\n",
    "        'Precision (%)': sum(precision_list) / len(precision_list) * 100,\n",
    "        'Recall (%)': sum(recall_list) / len(recall_list) * 100,\n",
    "        'F1-score (%)': sum(f1_list) / len(f1_list) * 100,\n",
    "        'AUC (%)': sum(auc_list) / len(auc_list) * 100,\n",
    "    }\n",
    "\n",
    "# Step 11: Display the results for Table 3\n",
    "print(\"Table 3: Performance of the classifiers:\")\n",
    "print(pd.DataFrame(results).transpose())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
